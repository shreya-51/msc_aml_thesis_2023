{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyd1rz813mEo"
      },
      "outputs": [],
      "source": [
        "## IMPORTS ##\n",
        "\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from scipy.linalg import kron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "UMAVkFc33pSZ",
        "outputId": "3ee931e2-9e51-47f5-b0b5-879f1e814dae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 250x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## GENERATE RANDOM GRAPH ##\n",
        "\n",
        "N = 4  # number of nodes\n",
        "p = 1  # probability of creating edge\n",
        "\n",
        "# generate random graph\n",
        "G = nx.erdos_renyi_graph(N, p)\n",
        "\n",
        "# visualize graph\n",
        "plt.figure(figsize=(2.5, 2.5))\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1Jo6jjc3sG7"
      },
      "outputs": [],
      "source": [
        "## CALCULATE A FROM GRAPH ##\n",
        "\n",
        "adj_matrix = nx.adjacency_matrix(G).todense()\n",
        "\n",
        "def get_A(adj_matrix):\n",
        "    \"\"\"\n",
        "    This function works given the following assumptions on the adjacency matrix:\n",
        "        1. square\n",
        "        2. symmetric (graph is undirected)\n",
        "        3. binary\n",
        "    \"\"\"\n",
        "\n",
        "    N_agents = adj_matrix.shape[0]  # num agents\n",
        "    A = np.zeros((2*N_agents, 2*N_agents)) # size of A will be 2*size of adj_matrix (to account for shared and local layers)\n",
        "\n",
        "    for i in range(N_agents):\n",
        "        agent_num = i + 1 # makes the math easier\n",
        "\n",
        "        # update local layer row (only depends on itself)\n",
        "        local_layer_index = (2 * agent_num) - 1\n",
        "        A[local_layer_index, local_layer_index] = 1\n",
        "\n",
        "        # update shared layer row\n",
        "        for j in range(N_agents):\n",
        "            constant = np.count_nonzero(adj_matrix[i, :]) + 1 # number of connections agent i has including itself\n",
        "            shared_layer_index = 2 * (agent_num - 1)\n",
        "            if adj_matrix[i, j] == 1 or j == i:\n",
        "                A[shared_layer_index, 2 * (j - 1)] = 1/constant\n",
        "    return A\n",
        "\n",
        "A = get_A(adj_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcy26Zat3tce"
      },
      "outputs": [],
      "source": [
        "## DEFINE NEURAL NETWORK ARCHITECTURE ##\n",
        "\n",
        "# shared layers only\n",
        "class SharedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SharedNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        shape_before_flatten = x.shape\n",
        "        x = x.view(-1, 32 * shape_before_flatten[2] * shape_before_flatten[3])\n",
        "        return x, shape_before_flatten\n",
        "\n",
        "# task-specific model\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, shared_net, output_dim):\n",
        "        super(Agent, self).__init__()\n",
        "        self.shared = shared_net\n",
        "        self.task_specific = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*2*2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, shape_before_flatten = self.shared(x)\n",
        "        x = x.view(shape_before_flatten)\n",
        "        x = self.task_specific(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOb38xqWpwdV",
        "outputId": "7d60d651-8f90-4a35-81e7-e51f7e342db4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  ],\n",
              "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  ],\n",
              "       [0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  ],\n",
              "       [0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  ],\n",
              "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxD7tRON3u-f",
        "outputId": "bae0a221-481c-4d21-b958-49f094ba08ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 185554494.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 27499589.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 44960352.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4674976.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## LOAD MNIST DATA ##\n",
        "\n",
        "# set up data loading for MNIST\n",
        "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(16),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# load train and test sets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# split into task specific datasets\n",
        "trainset_agent = [[(x, y) for x, y in trainset if y < 5], [(x, y - 5) for x, y in trainset if y >= 5]]\n",
        "\n",
        "# set up data loaders\n",
        "trainloader_agent = []\n",
        "for trainset in trainset_agent:\n",
        "    trainloader_agent.append(DataLoader(trainset, batch_size=32, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-Rt0Olq3w0n"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.nn.init import orthogonal_\n",
        "\n",
        "class CustomOpt(torch.optim.Optimizer):\n",
        "    def __init__(self, params, A, E, lr=0.01):\n",
        "        defaults = dict(lr=lr)\n",
        "        self.A = A\n",
        "        self.E = E\n",
        "        self.lr = lr/E\n",
        "\n",
        "        self.weights_store = None\n",
        "        self.psi = None\n",
        "        self.old_psi = None\n",
        "        self.phi = None\n",
        "\n",
        "        self.param_info = None\n",
        "        self.setup_weights = False\n",
        "\n",
        "        super(CustomOpt, self).__init__(params, defaults)\n",
        "\n",
        "    def singular_value(self, p):\n",
        "        try:\n",
        "            sv = math.sqrt(p.shape[0] / p.shape[1])\n",
        "            if p.dim() == 4:\n",
        "                sv /= math.sqrt(p.shape[2] * p.shape[3])\n",
        "            return sv\n",
        "        except:\n",
        "            print()\n",
        "            #print(p.shape)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def init_weights(self, params):\n",
        "        for group in params:\n",
        "            for p in group['params']:\n",
        "                if p.dim() == 2: orthogonal_(p)\n",
        "                if p.dim() == 4:\n",
        "                    for kx in range(p.shape[2]):\n",
        "                        for ky in range(p.shape[3]):\n",
        "                            orthogonal_(p[:,:,kx,ky])\n",
        "                if p.dim() == 1:\n",
        "                    continue # skip biases\n",
        "                p *= self.singular_value(p)\n",
        "\n",
        "    def get_shared_gradient(self):\n",
        "\n",
        "      final_grad_norm = 0\n",
        "      count = 0\n",
        "\n",
        "      for i, group in enumerate(self.param_groups):\n",
        "        for param in group['params']:\n",
        "          if i%2 == 0:\n",
        "            final_grad_norm += param.grad.norm()\n",
        "            count += 1\n",
        "          else:\n",
        "            print(\"\")\n",
        "      return final_grad_norm / count\n",
        "\n",
        "    def setup_params(self):\n",
        "        param_vector = []\n",
        "        grad_vector = []\n",
        "        #param_info = []\n",
        "        all_param_info = []\n",
        "\n",
        "        depth = 0\n",
        "        for group in self.param_groups:\n",
        "            for param in group['params']:\n",
        "                depth += param.numel()\n",
        "\n",
        "        G = 0\n",
        "\n",
        "        lr_vector = []\n",
        "\n",
        "        shared_grad = self.get_shared_gradient()\n",
        "\n",
        "        # lr calculation\n",
        "        for i, group in enumerate(self.param_groups):\n",
        "            for param in group['params']:\n",
        "                check = self.singular_value(param)\n",
        "                if check != None:\n",
        "                    if i%2 == 1:\n",
        "                      G += self.singular_value(param) * param.grad.norm().sum()\n",
        "                    else:\n",
        "                      G += self.singular_value(param) * shared_grad\n",
        "\n",
        "        # add\n",
        "        #G /= depth\n",
        "\n",
        "        log = math.log(0.5 * (1 + math.sqrt(1 + 4*G)))\n",
        "\n",
        "        for i, group in enumerate(self.param_groups):\n",
        "            group_lr_vector = []\n",
        "            for param in group['params']:\n",
        "                #print(param.numel())\n",
        "                check = self.singular_value(param)\n",
        "                if check == None:\n",
        "                    group_lr_vector.append([self.lr] * param.numel())\n",
        "                else:\n",
        "                    if i%2 == 1:\n",
        "                      factor = self.singular_value(param) / param.grad.norm(keepdim=True)\n",
        "                    else:\n",
        "                      # adjust dimensions of returned grad\n",
        "                      shared_grad_adjusted = torch.full_like(param.grad.norm(keepdim=True), shared_grad)\n",
        "                      factor = self.singular_value(param) / shared_grad_adjusted\n",
        "                    temp_lr = 1.0 * log / depth * torch.nan_to_num(factor) # set self.gain to 1.0 for now\n",
        "                    group_lr_vector.append([temp_lr.item()] * param.numel())\n",
        "            group_lr_vector = [item for sublist in group_lr_vector for item in sublist]\n",
        "            lr_vector.append(group_lr_vector)\n",
        "\n",
        "        # original param/grad setup\n",
        "        for group in self.param_groups:\n",
        "            flat_params = [param.view(-1) for param in group['params']]\n",
        "            flat_grads = [param.grad.view(-1) for param in group['params']]\n",
        "            param_info = []\n",
        "            start_idx = 0\n",
        "\n",
        "            for param, flat_param in zip(group['params'], flat_params):\n",
        "                end_idx = start_idx + flat_param.size(0)\n",
        "                param_info.append((param, start_idx, end_idx, param.size()))\n",
        "                start_idx = end_idx\n",
        "\n",
        "            try:\n",
        "                concat_params = torch.cat(flat_params)\n",
        "            except:\n",
        "                print(len(flat_params))\n",
        "                print(flat_params[0])\n",
        "            concat_grads = torch.cat(flat_grads)\n",
        "            param_vector.append(concat_params)\n",
        "            grad_vector.append(concat_grads)\n",
        "            all_param_info.append(param_info)\n",
        "\n",
        "        max_length = max([tensor.size(0) for tensor in param_vector])\n",
        "\n",
        "        param_vector = [torch.nn.functional.pad(tensor, (0, max_length - tensor.size(0))) for tensor in param_vector]\n",
        "        grad_vector = [torch.nn.functional.pad(tensor, (0, max_length - tensor.size(0))) for tensor in grad_vector]\n",
        "\n",
        "        param_matrix = torch.stack(param_vector)\n",
        "        grad_matrix = torch.stack(grad_vector)\n",
        "\n",
        "        return param_matrix, grad_matrix, all_param_info, lr_vector\n",
        "\n",
        "    def putback_params(self, updated_params_matrix, all_param_info):\n",
        "        for group_idx, param_info_list in enumerate(all_param_info):\n",
        "          updated_values_group = updated_params_matrix[group_idx]\n",
        "\n",
        "          for param_info in param_info_list:\n",
        "              param, start_idx, end_idx, original_shape = param_info\n",
        "              updated_values = updated_values_group[start_idx:end_idx]\n",
        "              param.data = updated_values.view(original_shape)\n",
        "\n",
        "    def local_step(self):\n",
        "        # set up params\n",
        "        param_matrix, grad_matrix, param_info, lr_matrix = self.setup_params()\n",
        "\n",
        "        max_len = max(len(sublist) for sublist in lr_matrix)\n",
        "        padded_lists = [sublist + [0] * (max_len - len(sublist)) for sublist in lr_matrix]\n",
        "        lr_matrix = torch.tensor(padded_lists)\n",
        "\n",
        "        if self.param_info == None:\n",
        "            self.param_info = param_info # should always be the same, therefore only assign it once\n",
        "\n",
        "        # if it is the first loop of E, save the current iteration's weights to be used to update phi at the end of the E loop\n",
        "        if self.weights_store == None:\n",
        "            self.weights_store = param_matrix.clone()\n",
        "\n",
        "        # update one E step\n",
        "        # param_matrix = param_matrix - self.lr * grad_matrix\n",
        "        param_matrix = param_matrix - lr_matrix * grad_matrix\n",
        "        self.psi = param_matrix.clone()\n",
        "\n",
        "        # put back params\n",
        "        self.putback_params(param_matrix, param_info)\n",
        "\n",
        "    def correct(self):\n",
        "        if self.old_psi == None:\n",
        "            phi = self.psi.clone()\n",
        "        else:\n",
        "            phi = self.weights_store + self.psi - self.old_psi\n",
        "\n",
        "        # store new old_psi\n",
        "        self.old_psi = self.psi.clone()\n",
        "\n",
        "        # reset weights_store for next epoch\n",
        "        self.weights_store = None\n",
        "\n",
        "        # store phi to update weights\n",
        "        self.phi = phi.clone()\n",
        "\n",
        "    def step(self):\n",
        "        # if it is the first step, intialize the weights\n",
        "        if self.setup_weights == False:\n",
        "            self.init_weights(self.param_groups)\n",
        "            self.setup_weights = True\n",
        "\n",
        "        # update weights+biases\n",
        "        torch_A = torch.from_numpy(self.A).float()\n",
        "        torch_A = 0.5 * (torch_A + torch.eye(torch_A.size(0)))\n",
        "        updated_params_matrix = torch.matmul(torch_A, self.phi)\n",
        "\n",
        "        # put back params\n",
        "        self.putback_params(updated_params_matrix, self.param_info)\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJpfLrp_36lI"
      },
      "outputs": [],
      "source": [
        "# initialize full task-specific networks (N copies of shared + local network architecture)\n",
        "shared_networks = []\n",
        "agent_networks = []\n",
        "for n in range(N):\n",
        "    shared_net = SharedNet()\n",
        "    shared_networks.append(shared_net)\n",
        "    agent_networks.append(Agent(shared_net, 5)) # 5 output classes to demonstrate with MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9te0X0p37y9"
      },
      "outputs": [],
      "source": [
        "param_list = []\n",
        "E = 2\n",
        "\n",
        "for network in agent_networks:\n",
        "    param_list.append({'params': network.shared.parameters()})\n",
        "    param_list.append({'params': network.task_specific.parameters()})\n",
        "\n",
        "optimizer = CustomOpt(param_list, A, E, lr=0.0025)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RNrK2KGx389d",
        "outputId": "f295d55b-288d-4747-8128-d469447e71dd"
      },
      "outputs": [],
      "source": [
        "agent1_losses = []\n",
        "agent2_losses = []\n",
        "agent3_losses = []\n",
        "agent4_losses = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    agent1_loss = 0.0\n",
        "    agent2_loss = 0.0\n",
        "    agent3_loss = 0.0\n",
        "    agent4_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for (inputs1, labels1), (inputs2, labels2) in zip(trainloader_agent[0], trainloader_agent[1]):\n",
        "        agent1 = agent_networks[0]\n",
        "        agent2 = agent_networks[1]\n",
        "        agent3 = agent_networks[2]\n",
        "        agent4 = agent_networks[3]\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # e loop\n",
        "        for e in range(E):\n",
        "            optimizer.zero_grad()\n",
        "            outputs1 = agent1(inputs1)\n",
        "            outputs2 = agent2(inputs2)\n",
        "            outputs3 = agent3(inputs1)\n",
        "            outputs4 = agent4(inputs2)\n",
        "\n",
        "            loss1 = criterion(outputs1, labels1)\n",
        "            loss2 = criterion(outputs2, labels2)\n",
        "            loss3 = criterion(outputs3, labels1)\n",
        "            loss4 = criterion(outputs4, labels2)\n",
        "\n",
        "            total_loss = loss1 + loss2 + loss3 + loss4\n",
        "            total_loss.backward()\n",
        "\n",
        "            optimizer.local_step()\n",
        "\n",
        "        # correction\n",
        "        optimizer.correct()\n",
        "\n",
        "        # update all weights_i\n",
        "        optimizer.step()\n",
        "\n",
        "        agent1_loss += loss1.item()\n",
        "        agent2_loss += loss2.item()\n",
        "        agent3_loss += loss3.item()\n",
        "        agent4_loss += loss4.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    agent1_loss /= num_batches\n",
        "    agent2_loss /= num_batches\n",
        "    agent1_losses.append(agent1_loss)\n",
        "    agent2_losses.append(agent2_loss)\n",
        "\n",
        "    agent3_loss /= num_batches\n",
        "    agent4_loss /= num_batches\n",
        "    agent3_losses.append(agent3_loss)\n",
        "    agent4_losses.append(agent4_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Agent1 Loss: {agent1_loss}, Agent2 Loss: {agent2_loss}, Agent3 Loss: {agent3_loss}, Agent4 Loss: {agent4_loss}')\n",
        "\n",
        "# After training is done, plot the losses\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(range(num_epochs), agent1_losses, label='Agent 1 Loss')\n",
        "plt.plot(range(num_epochs), agent2_losses, label='Agent 2 Loss')\n",
        "plt.plot(range(num_epochs), agent3_losses, label='Agent 3 Loss')\n",
        "plt.plot(range(num_epochs), agent4_losses, label='Agent 4 Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZipfR6pdps65"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"shared_agd_mnist.pkl\", \"wb\") as file:\n",
        "  pickle.dump((agent1_losses, agent2_losses, agent3_losses, agent4_losses), file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
