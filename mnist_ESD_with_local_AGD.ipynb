{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyd1rz813mEo"
      },
      "outputs": [],
      "source": [
        "## IMPORTS ##\n",
        "\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from scipy.linalg import kron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "UMAVkFc33pSZ",
        "outputId": "4de16159-ccaa-4ad1-9e5b-117d629b8241"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 250x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## GENERATE RANDOM GRAPH ##\n",
        "\n",
        "N = 4  # number of nodes\n",
        "p = 1  # probability of creating edge\n",
        "\n",
        "# generate random graph\n",
        "G = nx.erdos_renyi_graph(N, p)\n",
        "\n",
        "# visualize graph\n",
        "plt.figure(figsize=(2.5, 2.5))\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1Jo6jjc3sG7"
      },
      "outputs": [],
      "source": [
        "## CALCULATE A FROM GRAPH ##\n",
        "\n",
        "adj_matrix = nx.adjacency_matrix(G).todense()\n",
        "\n",
        "def get_A(adj_matrix):\n",
        "    \"\"\"\n",
        "    This function works given the following assumptions on the adjacency matrix:\n",
        "        1. square\n",
        "        2. symmetric (graph is undirected)\n",
        "        3. binary\n",
        "    \"\"\"\n",
        "\n",
        "    N_agents = adj_matrix.shape[0]  # num agents\n",
        "    A = np.zeros((2*N_agents, 2*N_agents)) # size of A will be 2*size of adj_matrix (to account for shared and local layers)\n",
        "\n",
        "    for i in range(N_agents):\n",
        "        agent_num = i + 1 # makes the math easier\n",
        "\n",
        "        # update local layer row (only depends on itself)\n",
        "        local_layer_index = (2 * agent_num) - 1\n",
        "        A[local_layer_index, local_layer_index] = 1\n",
        "\n",
        "        # update shared layer row\n",
        "        for j in range(N_agents):\n",
        "            constant = np.count_nonzero(adj_matrix[i, :]) + 1 # number of connections agent i has including itself\n",
        "            shared_layer_index = 2 * (agent_num - 1)\n",
        "            if adj_matrix[i, j] == 1 or j == i:\n",
        "                A[shared_layer_index, 2 * (j - 1)] = 1/constant\n",
        "    return A\n",
        "\n",
        "A = get_A(adj_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcy26Zat3tce"
      },
      "outputs": [],
      "source": [
        "## DEFINE NEURAL NETWORK ARCHITECTURE ##\n",
        "\n",
        "# shared layers only\n",
        "class SharedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SharedNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        shape_before_flatten = x.shape\n",
        "        x = x.view(-1, 32 * shape_before_flatten[2] * shape_before_flatten[3])\n",
        "        return x, shape_before_flatten\n",
        "\n",
        "# task-specific model\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, shared_net, output_dim):\n",
        "        super(Agent, self).__init__()\n",
        "        self.shared = shared_net\n",
        "        self.task_specific = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*2*2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, shape_before_flatten = self.shared(x)\n",
        "        x = x.view(shape_before_flatten)\n",
        "        x = self.task_specific(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxD7tRON3u-f",
        "outputId": "584a2180-5ead-43e0-f525-b635c5b6764a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 157172980.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 27599839.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 44560868.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9626340.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## LOAD MNIST DATA ##\n",
        "\n",
        "# set up data loading for MNIST\n",
        "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(16),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# load train and test sets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# split into task specific datasets\n",
        "trainset_agent = [[(x, y) for x, y in trainset if y < 5], [(x, y - 5) for x, y in trainset if y >= 5]]\n",
        "\n",
        "# set up data loaders\n",
        "trainloader_agent = []\n",
        "for trainset in trainset_agent:\n",
        "    trainloader_agent.append(DataLoader(trainset, batch_size=32, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-Rt0Olq3w0n"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.nn.init import orthogonal_\n",
        "\n",
        "class CustomOpt(torch.optim.Optimizer):\n",
        "    def __init__(self, params, A, E, lr=0.01):\n",
        "        defaults = dict(lr=lr)\n",
        "        self.A = A\n",
        "        self.E = E\n",
        "        self.lr = lr/E\n",
        "\n",
        "        self.weights_store = None\n",
        "        self.psi = None\n",
        "        self.old_psi = None\n",
        "        self.phi = None\n",
        "\n",
        "        self.param_info = None\n",
        "        self.setup_weights = False\n",
        "\n",
        "        super(CustomOpt, self).__init__(params, defaults)\n",
        "\n",
        "    def singular_value(self, p):\n",
        "        try:\n",
        "            sv = math.sqrt(p.shape[0] / p.shape[1])\n",
        "            if p.dim() == 4:\n",
        "                sv /= math.sqrt(p.shape[2] * p.shape[3])\n",
        "            return sv\n",
        "        except:\n",
        "            print()\n",
        "            #print(p.shape)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def init_weights(self, params):\n",
        "        for group in params:\n",
        "            for p in group['params']:\n",
        "                if p.dim() == 2: orthogonal_(p)\n",
        "                if p.dim() == 4:\n",
        "                    for kx in range(p.shape[2]):\n",
        "                        for ky in range(p.shape[3]):\n",
        "                            orthogonal_(p[:,:,kx,ky])\n",
        "                if p.dim() == 1:\n",
        "                    continue # skip biases\n",
        "                p *= self.singular_value(p)\n",
        "\n",
        "    def setup_params(self):\n",
        "        param_vector = []\n",
        "        grad_vector = []\n",
        "        #param_info = []\n",
        "        all_param_info = []\n",
        "\n",
        "        depth = 0\n",
        "        for group in self.param_groups:\n",
        "            for param in group['params']:\n",
        "                depth += param.numel()\n",
        "\n",
        "        G = 0\n",
        "\n",
        "        lr_vector = []\n",
        "\n",
        "        # lr calculation\n",
        "        for group in self.param_groups:\n",
        "            for param in group['params']:\n",
        "                check = self.singular_value(param)\n",
        "                if check != None:\n",
        "                    G += self.singular_value(param) * param.grad.norm().sum()\n",
        "\n",
        "        # add\n",
        "        #G /= depth\n",
        "\n",
        "        log = math.log(0.5 * (1 + math.sqrt(1 + 4*G)))\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            group_lr_vector = []\n",
        "            for param in group['params']:\n",
        "                #print(param.numel())\n",
        "                check = self.singular_value(param)\n",
        "                if check == None:\n",
        "                    group_lr_vector.append([self.lr] * param.numel())\n",
        "                else:\n",
        "                    factor = self.singular_value(param) / param.grad.norm(keepdim=True)\n",
        "                    temp_lr = 1.0 * log / depth * torch.nan_to_num(factor) # set self.gain to 1.0 for now\n",
        "                    group_lr_vector.append([temp_lr.item()] * param.numel())\n",
        "            group_lr_vector = [item for sublist in group_lr_vector for item in sublist]\n",
        "            lr_vector.append(group_lr_vector)\n",
        "\n",
        "        # original param/grad setup\n",
        "        for group in self.param_groups:\n",
        "            flat_params = [param.view(-1) for param in group['params']]\n",
        "            flat_grads = [param.grad.view(-1) for param in group['params']]\n",
        "            param_info = []\n",
        "            start_idx = 0\n",
        "\n",
        "            for param, flat_param in zip(group['params'], flat_params):\n",
        "                end_idx = start_idx + flat_param.size(0)\n",
        "                param_info.append((param, start_idx, end_idx, param.size()))\n",
        "                start_idx = end_idx\n",
        "\n",
        "            try:\n",
        "                concat_params = torch.cat(flat_params)\n",
        "            except:\n",
        "                print(len(flat_params))\n",
        "                print(flat_params[0])\n",
        "            concat_grads = torch.cat(flat_grads)\n",
        "            param_vector.append(concat_params)\n",
        "            grad_vector.append(concat_grads)\n",
        "            all_param_info.append(param_info)\n",
        "\n",
        "        max_length = max([tensor.size(0) for tensor in param_vector])\n",
        "\n",
        "        param_vector = [torch.nn.functional.pad(tensor, (0, max_length - tensor.size(0))) for tensor in param_vector]\n",
        "        grad_vector = [torch.nn.functional.pad(tensor, (0, max_length - tensor.size(0))) for tensor in grad_vector]\n",
        "\n",
        "        param_matrix = torch.stack(param_vector)\n",
        "        grad_matrix = torch.stack(grad_vector)\n",
        "\n",
        "        return param_matrix, grad_matrix, all_param_info, lr_vector\n",
        "\n",
        "    def putback_params(self, updated_params_matrix, all_param_info):\n",
        "        for group_idx, param_info_list in enumerate(all_param_info):\n",
        "          updated_values_group = updated_params_matrix[group_idx]\n",
        "\n",
        "          for param_info in param_info_list:\n",
        "              param, start_idx, end_idx, original_shape = param_info\n",
        "              updated_values = updated_values_group[start_idx:end_idx]\n",
        "              param.data = updated_values.view(original_shape)\n",
        "\n",
        "    def local_step(self):\n",
        "        # set up params\n",
        "        param_matrix, grad_matrix, param_info, lr_matrix = self.setup_params()\n",
        "\n",
        "        max_len = max(len(sublist) for sublist in lr_matrix)\n",
        "        padded_lists = [sublist + [0] * (max_len - len(sublist)) for sublist in lr_matrix]\n",
        "        lr_matrix = torch.tensor(padded_lists)\n",
        "\n",
        "        if self.param_info == None:\n",
        "            self.param_info = param_info # should always be the same, therefore only assign it once\n",
        "\n",
        "        # if it is the first loop of E, save the current iteration's weights to be used to update phi at the end of the E loop\n",
        "        if self.weights_store == None:\n",
        "            self.weights_store = param_matrix.clone()\n",
        "\n",
        "        # update one E step\n",
        "        # param_matrix = param_matrix - self.lr * grad_matrix\n",
        "        param_matrix = param_matrix - lr_matrix * grad_matrix\n",
        "        self.psi = param_matrix.clone()\n",
        "\n",
        "        # put back params\n",
        "        self.putback_params(param_matrix, param_info)\n",
        "\n",
        "    def correct(self):\n",
        "        if self.old_psi == None:\n",
        "            phi = self.psi.clone()\n",
        "        else:\n",
        "            phi = self.weights_store + self.psi - self.old_psi\n",
        "\n",
        "        # store new old_psi\n",
        "        self.old_psi = self.psi.clone()\n",
        "\n",
        "        # reset weights_store for next epoch\n",
        "        self.weights_store = None\n",
        "\n",
        "        # store phi to update weights\n",
        "        self.phi = phi.clone()\n",
        "\n",
        "    def step(self):\n",
        "        # if it is the first step, intialize the weights\n",
        "        if self.setup_weights == False:\n",
        "            self.init_weights(self.param_groups)\n",
        "            self.setup_weights = True\n",
        "\n",
        "        # update weights+biases\n",
        "        torch_A = torch.from_numpy(self.A).float()\n",
        "        torch_A = 0.5 * (torch_A + torch.eye(torch_A.size(0)))\n",
        "        updated_params_matrix = torch.matmul(torch_A, self.phi)\n",
        "\n",
        "        # put back params\n",
        "        self.putback_params(updated_params_matrix, self.param_info)\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJpfLrp_36lI"
      },
      "outputs": [],
      "source": [
        "# initialize full task-specific networks (N copies of shared + local network architecture)\n",
        "shared_networks = []\n",
        "agent_networks = []\n",
        "for n in range(N):\n",
        "    shared_net = SharedNet()\n",
        "    shared_networks.append(shared_net)\n",
        "    agent_networks.append(Agent(shared_net, 5)) # 5 output classes to demonstrate with MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9te0X0p37y9"
      },
      "outputs": [],
      "source": [
        "param_list = []\n",
        "E = 2\n",
        "\n",
        "for network in agent_networks:\n",
        "    param_list.append({'params': network.shared.parameters()})\n",
        "    param_list.append({'params': network.task_specific.parameters()})\n",
        "\n",
        "optimizer = CustomOpt(param_list, A, E, lr=0.0025)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RNrK2KGx389d",
        "outputId": "1749252d-301b-4e94-a868-32a706d79f1b"
      },
      "outputs": [],
      "source": [
        "agent1_losses = []\n",
        "agent2_losses = []\n",
        "agent3_losses = []\n",
        "agent4_losses = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    agent1_loss = 0.0\n",
        "    agent2_loss = 0.0\n",
        "    agent3_loss = 0.0\n",
        "    agent4_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for (inputs1, labels1), (inputs2, labels2) in zip(trainloader_agent[0], trainloader_agent[1]):\n",
        "        agent1 = agent_networks[0]\n",
        "        agent2 = agent_networks[1]\n",
        "        agent3 = agent_networks[2]\n",
        "        agent4 = agent_networks[3]\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # e loop\n",
        "        for e in range(E):\n",
        "            optimizer.zero_grad()\n",
        "            outputs1 = agent1(inputs1)\n",
        "            outputs2 = agent2(inputs2)\n",
        "            outputs3 = agent3(inputs1)\n",
        "            outputs4 = agent4(inputs2)\n",
        "\n",
        "            loss1 = criterion(outputs1, labels1)\n",
        "            loss2 = criterion(outputs2, labels2)\n",
        "            loss3 = criterion(outputs3, labels1)\n",
        "            loss4 = criterion(outputs4, labels2)\n",
        "\n",
        "            total_loss = loss1 + loss2 + loss3 + loss4\n",
        "            total_loss.backward()\n",
        "\n",
        "            optimizer.local_step()\n",
        "\n",
        "        # correction\n",
        "        optimizer.correct()\n",
        "\n",
        "        # update all weights_i\n",
        "        optimizer.step()\n",
        "\n",
        "        agent1_loss += loss1.item()\n",
        "        agent2_loss += loss2.item()\n",
        "        agent3_loss += loss3.item()\n",
        "        agent4_loss += loss4.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    agent1_loss /= num_batches\n",
        "    agent2_loss /= num_batches\n",
        "    agent1_losses.append(agent1_loss)\n",
        "    agent2_losses.append(agent2_loss)\n",
        "\n",
        "    agent3_loss /= num_batches\n",
        "    agent4_loss /= num_batches\n",
        "    agent3_losses.append(agent3_loss)\n",
        "    agent4_losses.append(agent4_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Agent1 Loss: {agent1_loss}, Agent2 Loss: {agent2_loss}, Agent3 Loss: {agent3_loss}, Agent4 Loss: {agent4_loss}')\n",
        "\n",
        "# After training is done, plot the losses\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(range(num_epochs), agent1_losses, label='Agent 1 Loss')\n",
        "plt.plot(range(num_epochs), agent2_losses, label='Agent 2 Loss')\n",
        "plt.plot(range(num_epochs), agent3_losses, label='Agent 3 Loss')\n",
        "plt.plot(range(num_epochs), agent4_losses, label='Agent 4 Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY3unOSqgHD6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"local_agd_mnist.pkl\", \"wb\") as file:\n",
        "  pickle.dump((agent1_losses, agent2_losses, agent3_losses, agent4_losses), file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
