{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KojCKv4eeX0c"
      },
      "outputs": [],
      "source": [
        "## IMPORTS ##\n",
        "\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from scipy.linalg import kron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Ec-LWkYMeX0d",
        "outputId": "d1a0ad3b-8350-4220-9977-6f1e41de7e2b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 250x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## GENERATE RANDOM GRAPH ##\n",
        "\n",
        "N = 4  # number of nodes\n",
        "p = 1  # probability of creating edge\n",
        "\n",
        "# generate random graph\n",
        "G = nx.erdos_renyi_graph(N, p)\n",
        "\n",
        "# visualize graph\n",
        "plt.figure(figsize=(2.5, 2.5))\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM7c2fSPeX0d"
      },
      "outputs": [],
      "source": [
        "## CALCULATE A FROM GRAPH ##\n",
        "\n",
        "adj_matrix = nx.adjacency_matrix(G).todense()\n",
        "\n",
        "def get_A(adj_matrix):\n",
        "    \"\"\"\n",
        "    This function works given the following assumptions on the adjacency matrix:\n",
        "        1. square\n",
        "        2. symmetric (graph is undirected)\n",
        "        3. binary\n",
        "    \"\"\"\n",
        "\n",
        "    N_agents = adj_matrix.shape[0]  # num agents\n",
        "    A = np.zeros((2*N_agents, 2*N_agents)) # size of A will be 2*size of adj_matrix (to account for shared and local layers)\n",
        "\n",
        "    for i in range(N_agents):\n",
        "        agent_num = i + 1 # makes the math easier\n",
        "\n",
        "        # update local layer row (only depends on itself)\n",
        "        local_layer_index = (2 * agent_num) - 1\n",
        "        A[local_layer_index, local_layer_index] = 1\n",
        "\n",
        "        # update shared layer row\n",
        "        for j in range(N_agents):\n",
        "            constant = np.count_nonzero(adj_matrix[i, :]) + 1 # number of connections agent i has including itself\n",
        "            shared_layer_index = 2 * (agent_num - 1)\n",
        "            if adj_matrix[i, j] == 1 or j == i:\n",
        "                A[shared_layer_index, 2 * (j - 1)] = 1/constant\n",
        "    return A\n",
        "\n",
        "A = get_A(adj_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seOiSyLzeX0e"
      },
      "outputs": [],
      "source": [
        "## DEFINE NEURAL NETWORK ARCHITECTURE ##\n",
        "\n",
        "# shared layers only\n",
        "class SharedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SharedNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        shape_before_flatten = x.shape\n",
        "        x = x.view(-1, 32 * shape_before_flatten[2] * shape_before_flatten[3])\n",
        "        return x, shape_before_flatten\n",
        "\n",
        "# task-specific model\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, shared_net, output_dim):\n",
        "        super(Agent, self).__init__()\n",
        "        self.shared = shared_net\n",
        "        self.task_specific = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*2*2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, shape_before_flatten = self.shared(x)\n",
        "        x = x.view(shape_before_flatten)\n",
        "        x = self.task_specific(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WitZqTH_eX0e"
      },
      "source": [
        "## EXAMPLE WITH MNIST ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ovquzSSeX0e",
        "outputId": "a831d60b-e98b-4bd7-b34b-6bb788b96b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 83233823.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31036560.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 22905460.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21623755.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## LOAD MNIST DATA ##\n",
        "\n",
        "# set up data loading for MNIST\n",
        "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(16),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# load train and test sets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# split into task specific datasets\n",
        "trainset_agent = [[(x, y) for x, y in trainset if y < 5], [(x, y - 5) for x, y in trainset if y >= 5]]\n",
        "\n",
        "# set up data loaders\n",
        "trainloader_agent = []\n",
        "for trainset in trainset_agent:\n",
        "    trainloader_agent.append(DataLoader(trainset, batch_size=32, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtyfRXRzfzdi"
      },
      "outputs": [],
      "source": [
        "# # Calculate training and validation sizes for each agent's data\n",
        "# train_size_agent1 = int(0.8 * len(trainset_agent[0]))\n",
        "# val_size_agent1 = len(trainset_agent[0]) - train_size_agent1\n",
        "\n",
        "# train_size_agent2 = int(0.8 * len(trainset_agent[1]))\n",
        "# val_size_agent2 = len(trainset_agent[1]) - train_size_agent2\n",
        "\n",
        "# # Split the data\n",
        "# train_dataset_agent1, val_dataset_agent1 = torch.utils.data.random_split(trainset_agent[0], [train_size_agent1, val_size_agent1])\n",
        "# train_dataset_agent2, val_dataset_agent2 = torch.utils.data.random_split(trainset_agent[1], [train_size_agent2, val_size_agent2])\n",
        "\n",
        "# # Create DataLoader for validation sets\n",
        "# valloader_agent1 = DataLoader(val_dataset_agent1, batch_size=32, shuffle=False)\n",
        "# valloader_agent2 = DataLoader(val_dataset_agent2, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6LOIsMreX0f"
      },
      "outputs": [],
      "source": [
        "class CustomOpt(torch.optim.Optimizer):\n",
        "    def __init__(self, params, A, E, lr=0.01):\n",
        "        defaults = dict(lr=lr)\n",
        "        self.A = A\n",
        "        self.E = E\n",
        "        self.lr = lr/E\n",
        "\n",
        "        self.weights_store = None\n",
        "        self.psi = None\n",
        "        self.old_psi = None\n",
        "        self.phi = None\n",
        "\n",
        "        self.param_info = None\n",
        "\n",
        "        super(CustomOpt, self).__init__(params, defaults)\n",
        "\n",
        "    def setup_params(self):\n",
        "        param_vector = []\n",
        "        grad_vector = []\n",
        "        #param_info = []\n",
        "        all_param_info = []\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            flat_params = [param.view(-1) for param in group['params']]\n",
        "            flat_grads = [param.grad.view(-1) for param in group['params']]\n",
        "            param_info = []\n",
        "            start_idx = 0\n",
        "\n",
        "            for param, flat_param in zip(group['params'], flat_params):\n",
        "                end_idx = start_idx + flat_param.size(0)\n",
        "                param_info.append((param, start_idx, end_idx, param.size()))\n",
        "                start_idx = end_idx\n",
        "\n",
        "            concat_params = torch.cat(flat_params)\n",
        "            concat_grads = torch.cat(flat_grads)\n",
        "            param_vector.append(concat_params)\n",
        "            grad_vector.append(concat_grads)\n",
        "            all_param_info.append(param_info)\n",
        "\n",
        "        max_length = max([tensor.size(0) for tensor in param_vector])\n",
        "\n",
        "        param_vector = [torch.nn.functional.pad(tensor, (0, max_length - tensor.size(0))) for tensor in param_vector]\n",
        "        grad_vector = [torch.nn.functional.pad(tensor, (0, max_length - tensor.size(0))) for tensor in grad_vector]\n",
        "\n",
        "        param_matrix = torch.stack(param_vector)\n",
        "        grad_matrix = torch.stack(grad_vector)\n",
        "\n",
        "        return param_matrix, grad_matrix, all_param_info\n",
        "\n",
        "    def putback_params(self, updated_params_matrix, all_param_info):\n",
        "        for group_idx, param_info_list in enumerate(all_param_info):\n",
        "          updated_values_group = updated_params_matrix[group_idx]\n",
        "\n",
        "          for param_info in param_info_list:\n",
        "              param, start_idx, end_idx, original_shape = param_info\n",
        "              updated_values = updated_values_group[start_idx:end_idx]\n",
        "              param.data = updated_values.view(original_shape)\n",
        "\n",
        "    def local_step(self):\n",
        "        # set up params\n",
        "        param_matrix, grad_matrix, param_info = self.setup_params()\n",
        "\n",
        "        if self.param_info == None:\n",
        "            self.param_info = param_info # should always be the same, therefore only assign it once\n",
        "\n",
        "        # if it is the first loop of E, save the current iteration's weights to be used to update phi at the end of the E loop\n",
        "        if self.weights_store == None:\n",
        "            self.weights_store = param_matrix.clone()\n",
        "\n",
        "        # update one E step\n",
        "        param_matrix = param_matrix - self.lr * grad_matrix\n",
        "        self.psi = param_matrix.clone().detach()\n",
        "\n",
        "        # put back params\n",
        "        self.putback_params(param_matrix, param_info)\n",
        "\n",
        "    def correct(self):\n",
        "        if self.old_psi == None:\n",
        "            phi = self.psi.clone().detach()\n",
        "        else:\n",
        "            phi = self.weights_store + self.psi - self.old_psi\n",
        "\n",
        "        # store new old_psi\n",
        "        self.old_psi = self.psi.clone().detach()\n",
        "\n",
        "        # reset weights_store for next epoch\n",
        "        self.weights_store = None\n",
        "\n",
        "        # store phi to update weights\n",
        "        self.phi = phi.clone().detach()\n",
        "\n",
        "    def step(self):\n",
        "        # update weights+biases\n",
        "        torch_A = torch.from_numpy(self.A).float()\n",
        "        torch_A = 0.5 * (torch_A + torch.eye(torch_A.size(0)))\n",
        "        updated_params_matrix = torch.matmul(torch_A, self.phi)\n",
        "\n",
        "        # put back params\n",
        "        self.putback_params(updated_params_matrix, self.param_info)\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li9ueDZ3eX0f"
      },
      "outputs": [],
      "source": [
        "# initialize full task-specific networks (N copies of shared + local network architecture)\n",
        "shared_networks = []\n",
        "agent_networks = []\n",
        "for n in range(N):\n",
        "    shared_net = SharedNet()\n",
        "    shared_networks.append(shared_net)\n",
        "    agent_networks.append(Agent(shared_net, 5)) # 5 output classes to demonstrate with MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzZw66ubeX0f"
      },
      "outputs": [],
      "source": [
        "param_list = []\n",
        "E = 2\n",
        "\n",
        "for network in agent_networks:\n",
        "    param_list.append({'params': network.shared.parameters()})\n",
        "    param_list.append({'params': network.task_specific.parameters()})\n",
        "\n",
        "optimizer = CustomOpt(param_list, A, E, lr=0.0025)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "awRw84dUeX0f",
        "outputId": "6280056a-2731-46ea-f400-7a4729d193a5"
      },
      "outputs": [],
      "source": [
        "agent1_losses = []\n",
        "agent2_losses = []\n",
        "agent3_losses = []\n",
        "agent4_losses = []\n",
        "\n",
        "agent1_gradients = []\n",
        "agent2_gradients = []\n",
        "agent3_gradients = []\n",
        "agent4_gradients = []\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    agent1_loss = 0.0\n",
        "    agent2_loss = 0.0\n",
        "    agent3_loss = 0.0\n",
        "    agent4_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for (inputs1, labels1), (inputs2, labels2) in zip(trainloader_agent[0], trainloader_agent[1]):\n",
        "        agent1 = agent_networks[0]\n",
        "        agent2 = agent_networks[1]\n",
        "        agent3 = agent_networks[2]\n",
        "        agent4 = agent_networks[3]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # e loop\n",
        "        for e in range(E):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs1 = agent1(inputs1)\n",
        "            outputs2 = agent2(inputs2)\n",
        "            outputs3 = agent3(inputs1)\n",
        "            outputs4 = agent4(inputs2)\n",
        "\n",
        "            loss1 = criterion(outputs1, labels1)\n",
        "            loss2 = criterion(outputs2, labels2)\n",
        "            loss3 = criterion(outputs3, labels1)\n",
        "            loss4 = criterion(outputs4, labels2)\n",
        "\n",
        "            total_loss = loss1 + loss2 + loss3 + loss4\n",
        "            total_loss.backward()\n",
        "\n",
        "            optimizer.local_step()\n",
        "\n",
        "        # correction\n",
        "        optimizer.correct()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        agent1_loss += loss1.item()\n",
        "        agent2_loss += loss2.item()\n",
        "        agent3_loss += loss3.item()\n",
        "        agent4_loss += loss4.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    agent1_loss /= num_batches\n",
        "    agent2_loss /= num_batches\n",
        "    agent1_losses.append(agent1_loss)\n",
        "    agent2_losses.append(agent2_loss)\n",
        "\n",
        "    agent3_loss /= num_batches\n",
        "    agent4_loss /= num_batches\n",
        "    agent3_losses.append(agent3_loss)\n",
        "    agent4_losses.append(agent4_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Agent1 Loss: {agent1_loss}, Agent2 Loss: {agent2_loss}, Agent3 Loss: {agent3_loss}, Agent4 Loss: {agent4_loss}')\n",
        "\n",
        "# plot log loss instead:\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Take 10*log10 of the losses\n",
        "agent1_losses_log = 10 * np.log10(agent1_losses)\n",
        "agent2_losses_log = 10 * np.log10(agent2_losses)\n",
        "agent3_losses_log = 10 * np.log10(agent3_losses)\n",
        "agent4_losses_log = 10 * np.log10(agent4_losses)\n",
        "\n",
        "# Plot the transformed losses\n",
        "plt.plot(range(num_epochs), agent1_losses_log, label='Agent 1 Loss (10*log10)')\n",
        "plt.plot(range(num_epochs), agent2_losses_log, label='Agent 2 Loss (10*log10)')\n",
        "plt.plot(range(num_epochs), agent3_losses_log, label='Agent 3 Loss (10*log10)')\n",
        "plt.plot(range(num_epochs), agent4_losses_log, label='Agent 4 Loss (10*log10)')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (10*log10)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting validation losses\n",
        "# plt.figure(figsize=(10, 7))\n",
        "# agent1_val_losses, agent2_val_losses = zip(*val_losses)\n",
        "# plt.plot(range(num_epochs), agent1_val_losses, label='Validation Agent 1 Loss')\n",
        "# plt.plot(range(num_epochs), agent2_val_losses, label='Validation Agent 2 Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Validation Loss')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHxWQpOflnCm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"primal_dual_mnist.pkl\", \"wb\") as file:\n",
        "  pickle.dump((agent1_losses, agent2_losses, agent3_losses, agent4_losses), file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
